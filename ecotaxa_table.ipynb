{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf5af7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install packages and load libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from datetime import datetime, timezone\n",
    "import shutil\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86c85e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4560 deep feature records from 35 files.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>object_major</th>\n",
       "      <th>object_minor</th>\n",
       "      <th>object_area</th>\n",
       "      <th>object_circularity</th>\n",
       "      <th>object_perimeter</th>\n",
       "      <th>object_width</th>\n",
       "      <th>object_height</th>\n",
       "      <th>object_sharpness</th>\n",
       "      <th>object_saturation</th>\n",
       "      <th>object_redness</th>\n",
       "      <th>object_greeness</th>\n",
       "      <th>object_blueness</th>\n",
       "      <th>object_colorfulness</th>\n",
       "      <th>object_speciesID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20250127_175115.761.0.png</td>\n",
       "      <td>61.109840</td>\n",
       "      <td>39.730301</td>\n",
       "      <td>1134.5</td>\n",
       "      <td>0.134707</td>\n",
       "      <td>325.320848</td>\n",
       "      <td>60</td>\n",
       "      <td>48</td>\n",
       "      <td>287.186931</td>\n",
       "      <td>86.849626</td>\n",
       "      <td>44.881410</td>\n",
       "      <td>46.264690</td>\n",
       "      <td>41.541667</td>\n",
       "      <td>25.418107</td>\n",
       "      <td>acantharea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20250127_182854.570.0.png</td>\n",
       "      <td>87.294754</td>\n",
       "      <td>44.348526</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>0.097350</td>\n",
       "      <td>447.303603</td>\n",
       "      <td>56</td>\n",
       "      <td>98</td>\n",
       "      <td>679.520833</td>\n",
       "      <td>97.125661</td>\n",
       "      <td>57.013228</td>\n",
       "      <td>56.994213</td>\n",
       "      <td>43.671296</td>\n",
       "      <td>51.950046</td>\n",
       "      <td>acantharea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20250129_224543.614.0.png</td>\n",
       "      <td>94.639442</td>\n",
       "      <td>43.623070</td>\n",
       "      <td>2123.0</td>\n",
       "      <td>0.164367</td>\n",
       "      <td>402.877197</td>\n",
       "      <td>98</td>\n",
       "      <td>56</td>\n",
       "      <td>243.814675</td>\n",
       "      <td>83.703869</td>\n",
       "      <td>56.118132</td>\n",
       "      <td>55.747024</td>\n",
       "      <td>68.444139</td>\n",
       "      <td>25.538225</td>\n",
       "      <td>acantharea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20250129_224803.015.0.png</td>\n",
       "      <td>57.560436</td>\n",
       "      <td>41.655426</td>\n",
       "      <td>1622.0</td>\n",
       "      <td>0.295141</td>\n",
       "      <td>262.793937</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>172.101260</td>\n",
       "      <td>66.433532</td>\n",
       "      <td>54.522619</td>\n",
       "      <td>54.848115</td>\n",
       "      <td>64.574206</td>\n",
       "      <td>28.898972</td>\n",
       "      <td>acantharea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20250130_111618.661.0.png</td>\n",
       "      <td>94.784340</td>\n",
       "      <td>31.535536</td>\n",
       "      <td>1316.0</td>\n",
       "      <td>0.108239</td>\n",
       "      <td>390.877197</td>\n",
       "      <td>44</td>\n",
       "      <td>112</td>\n",
       "      <td>1221.368467</td>\n",
       "      <td>94.418831</td>\n",
       "      <td>72.232143</td>\n",
       "      <td>71.717127</td>\n",
       "      <td>76.379058</td>\n",
       "      <td>42.586178</td>\n",
       "      <td>acantharea</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    filename  object_major  object_minor  object_area  \\\n",
       "0  20250127_175115.761.0.png     61.109840     39.730301       1134.5   \n",
       "1  20250127_182854.570.0.png     87.294754     44.348526       1550.0   \n",
       "2  20250129_224543.614.0.png     94.639442     43.623070       2123.0   \n",
       "3  20250129_224803.015.0.png     57.560436     41.655426       1622.0   \n",
       "4  20250130_111618.661.0.png     94.784340     31.535536       1316.0   \n",
       "\n",
       "   object_circularity  object_perimeter  object_width  object_height  \\\n",
       "0            0.134707        325.320848            60             48   \n",
       "1            0.097350        447.303603            56             98   \n",
       "2            0.164367        402.877197            98             56   \n",
       "3            0.295141        262.793937            63             53   \n",
       "4            0.108239        390.877197            44            112   \n",
       "\n",
       "   object_sharpness  object_saturation  object_redness  object_greeness  \\\n",
       "0        287.186931          86.849626       44.881410        46.264690   \n",
       "1        679.520833          97.125661       57.013228        56.994213   \n",
       "2        243.814675          83.703869       56.118132        55.747024   \n",
       "3        172.101260          66.433532       54.522619        54.848115   \n",
       "4       1221.368467          94.418831       72.232143        71.717127   \n",
       "\n",
       "   object_blueness  object_colorfulness object_speciesID  \n",
       "0        41.541667            25.418107       acantharea  \n",
       "1        43.671296            51.950046       acantharea  \n",
       "2        68.444139            25.538225       acantharea  \n",
       "3        64.574206            28.898972       acantharea  \n",
       "4        76.379058            42.586178       acantharea  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2. Load and Aggregate Deep Feature Data\n",
    "\n",
    "# Define the path to the main classified directory\n",
    "dir_path = \"classified_output\"\n",
    "\n",
    "all_ellipse_dfs = []\n",
    "ellipse_files = glob.glob(os.path.join(dir_path, \"**\", \"ellipse_data_*.csv\"), recursive=True)\n",
    "\n",
    "for file in ellipse_files:\n",
    "    # Extract the taxon name from the filename\n",
    "    taxon_name = Path(file).stem.replace(\"ellipse_data_\", \"\")\n",
    "    \n",
    "    temp_df = pd.read_csv(file)\n",
    "    temp_df['object_speciesID'] = taxon_name # Add the taxon name as a column\n",
    "    all_ellipse_dfs.append(temp_df)\n",
    "\n",
    "# Combine all data into a single master DataFrame\n",
    "master_df = pd.concat(all_ellipse_dfs, ignore_index=True)\n",
    "\n",
    "print(f\"Loaded {len(master_df)} deep feature records from {len(ellipse_files)} files.\")\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98d00aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFER data loaded and filtered to the following columns:\n",
      "['keyfield', 'cruise_id', 'GMT.datetime', 'station', 'lat_dec', 'lon_dec', 'depth', 'temp', 'sal', 'chl', 'o2_ctd', 'no3_no2', 'nh4', 'po4', 'si']\n"
     ]
    }
   ],
   "source": [
    "## 3. Load and Prepare SFER Cruise Data\n",
    "\n",
    "# Load SFER_data.csv from the parent 'plankton_imaging' directory\n",
    "sfer_path = os.path.join(Path(dir_path).parent, 'SFER_data.csv')\n",
    "sfer_data = pd.read_csv(sfer_path, low_memory=False)\n",
    "\n",
    "# Create a proper datetime column for merging\n",
    "sfer_data['GMT.datetime'] = pd.to_datetime(sfer_data['datetime'], format='mixed', errors='coerce')\n",
    "\n",
    "# Define the specific fields you want to merge from the SFER data\n",
    "sfer_fields_to_merge = [\n",
    "    'keyfield',\n",
    "    'cruise_id',\n",
    "    'GMT.datetime', # This key is required for the merge itself\n",
    "    'station',\n",
    "    'lat_dec',\n",
    "    'lon_dec',\n",
    "    'depth',\n",
    "    'temp',\n",
    "    'sal',\n",
    "    'chl',\n",
    "    'o2_ctd',\n",
    "    'no3_no2',\n",
    "    'nh4',\n",
    "    'po4',\n",
    "    'si'\n",
    "]\n",
    "\n",
    "# Create a new, smaller DataFrame with only the required columns and sort it\n",
    "sfer_data_filtered = sfer_data[sfer_fields_to_merge].sort_values('GMT.datetime')\n",
    "\n",
    "print(\"SFER data loaded and filtered to the following columns:\")\n",
    "print(sfer_data_filtered.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db76e383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully merged image data with SFER cruise data.\n",
      "Final table shape: (4560, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_file_name</th>\n",
       "      <th>object_major</th>\n",
       "      <th>object_minor</th>\n",
       "      <th>object_area</th>\n",
       "      <th>object_circularity</th>\n",
       "      <th>object_perimeter</th>\n",
       "      <th>object_width</th>\n",
       "      <th>object_height</th>\n",
       "      <th>object_sharpness</th>\n",
       "      <th>object_saturation</th>\n",
       "      <th>...</th>\n",
       "      <th>lon_dec</th>\n",
       "      <th>depth</th>\n",
       "      <th>temp</th>\n",
       "      <th>sal</th>\n",
       "      <th>chl</th>\n",
       "      <th>o2_ctd</th>\n",
       "      <th>no3_no2</th>\n",
       "      <th>nh4</th>\n",
       "      <th>po4</th>\n",
       "      <th>si</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20250127_174616.568.0.png</td>\n",
       "      <td>51.203804</td>\n",
       "      <td>19.600698</td>\n",
       "      <td>628.0</td>\n",
       "      <td>0.364936</td>\n",
       "      <td>147.053823</td>\n",
       "      <td>32</td>\n",
       "      <td>46</td>\n",
       "      <td>142.890039</td>\n",
       "      <td>98.736111</td>\n",
       "      <td>...</td>\n",
       "      <td>-82.8894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0796</td>\n",
       "      <td>36.753</td>\n",
       "      <td>0.395777</td>\n",
       "      <td>7.631</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20250127_174617.260.0.png</td>\n",
       "      <td>124.038612</td>\n",
       "      <td>19.411459</td>\n",
       "      <td>1507.0</td>\n",
       "      <td>0.216990</td>\n",
       "      <td>295.421354</td>\n",
       "      <td>52</td>\n",
       "      <td>86</td>\n",
       "      <td>54.962349</td>\n",
       "      <td>107.958821</td>\n",
       "      <td>...</td>\n",
       "      <td>-82.8894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0796</td>\n",
       "      <td>36.753</td>\n",
       "      <td>0.395777</td>\n",
       "      <td>7.631</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20250127_174617.864.0.png</td>\n",
       "      <td>30.025755</td>\n",
       "      <td>27.661806</td>\n",
       "      <td>629.0</td>\n",
       "      <td>0.702371</td>\n",
       "      <td>106.083260</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>204.216392</td>\n",
       "      <td>111.376705</td>\n",
       "      <td>...</td>\n",
       "      <td>-82.8894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0796</td>\n",
       "      <td>36.753</td>\n",
       "      <td>0.395777</td>\n",
       "      <td>7.631</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20250127_174645.761.0.png</td>\n",
       "      <td>142.024139</td>\n",
       "      <td>18.894503</td>\n",
       "      <td>1992.5</td>\n",
       "      <td>0.236171</td>\n",
       "      <td>325.605119</td>\n",
       "      <td>116</td>\n",
       "      <td>78</td>\n",
       "      <td>48.962889</td>\n",
       "      <td>107.934524</td>\n",
       "      <td>...</td>\n",
       "      <td>-82.8894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0796</td>\n",
       "      <td>36.753</td>\n",
       "      <td>0.395777</td>\n",
       "      <td>7.631</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20250127_174647.864.0.png</td>\n",
       "      <td>74.323059</td>\n",
       "      <td>16.697430</td>\n",
       "      <td>820.0</td>\n",
       "      <td>0.236234</td>\n",
       "      <td>208.852812</td>\n",
       "      <td>34</td>\n",
       "      <td>72</td>\n",
       "      <td>486.585260</td>\n",
       "      <td>119.326042</td>\n",
       "      <td>...</td>\n",
       "      <td>-82.8894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0796</td>\n",
       "      <td>36.753</td>\n",
       "      <td>0.395777</td>\n",
       "      <td>7.631</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               img_file_name  object_major  object_minor  object_area  \\\n",
       "0  20250127_174616.568.0.png     51.203804     19.600698        628.0   \n",
       "1  20250127_174617.260.0.png    124.038612     19.411459       1507.0   \n",
       "2  20250127_174617.864.0.png     30.025755     27.661806        629.0   \n",
       "3  20250127_174645.761.0.png    142.024139     18.894503       1992.5   \n",
       "4  20250127_174647.864.0.png     74.323059     16.697430        820.0   \n",
       "\n",
       "   object_circularity  object_perimeter  object_width  object_height  \\\n",
       "0            0.364936        147.053823            32             46   \n",
       "1            0.216990        295.421354            52             86   \n",
       "2            0.702371        106.083260            30             30   \n",
       "3            0.236171        325.605119           116             78   \n",
       "4            0.236234        208.852812            34             72   \n",
       "\n",
       "   object_sharpness  object_saturation  ...  lon_dec  depth     temp     sal  \\\n",
       "0        142.890039          98.736111  ... -82.8894    0.0  18.0796  36.753   \n",
       "1         54.962349         107.958821  ... -82.8894    0.0  18.0796  36.753   \n",
       "2        204.216392         111.376705  ... -82.8894    0.0  18.0796  36.753   \n",
       "3         48.962889         107.934524  ... -82.8894    0.0  18.0796  36.753   \n",
       "4        486.585260         119.326042  ... -82.8894    0.0  18.0796  36.753   \n",
       "\n",
       "        chl o2_ctd no3_no2   nh4   po4   si  \n",
       "0  0.395777  7.631    0.05  0.42  0.07  0.7  \n",
       "1  0.395777  7.631    0.05  0.42  0.07  0.7  \n",
       "2  0.395777  7.631    0.05  0.42  0.07  0.7  \n",
       "3  0.395777  7.631    0.05  0.42  0.07  0.7  \n",
       "4  0.395777  7.631    0.05  0.42  0.07  0.7  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 4. Merge Image Data with Cruise Data\n",
    "\n",
    "# Prepare the master DataFrame for merging\n",
    "master_df = master_df.rename(columns={'filename': 'img_file_name'})\n",
    "master_df['datetime'] = pd.to_datetime(master_df['img_file_name'].str.slice(0, 19), format='%Y%m%d_%H%M%S.%f')\n",
    "master_df = master_df.sort_values('datetime')\n",
    "\n",
    "# Merge the complete image list with the filtered SFER cruise data\n",
    "final_table = pd.merge_asof(\n",
    "    master_df,\n",
    "    sfer_data_filtered,\n",
    "    left_on='datetime',\n",
    "    right_on='GMT.datetime',\n",
    "    direction='nearest'\n",
    ")\n",
    "\n",
    "print(\"\\nSuccessfully merged image data with SFER cruise data.\")\n",
    "print(f\"Final table shape: {final_table.shape}\")\n",
    "final_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f59d686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Acquisition ID: export_4560_20250911_0010_sfer\n",
      "\n",
      "Final EcoTaxa table created. Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_file_name</th>\n",
       "      <th>object_id</th>\n",
       "      <th>object_date</th>\n",
       "      <th>object_time</th>\n",
       "      <th>object_lat</th>\n",
       "      <th>object_lon</th>\n",
       "      <th>object_major</th>\n",
       "      <th>object_minor</th>\n",
       "      <th>object_area</th>\n",
       "      <th>object_circularity</th>\n",
       "      <th>...</th>\n",
       "      <th>object_height</th>\n",
       "      <th>object_sharpness</th>\n",
       "      <th>object_saturation</th>\n",
       "      <th>object_redness</th>\n",
       "      <th>object_greeness</th>\n",
       "      <th>object_blueness</th>\n",
       "      <th>object_colorfulness</th>\n",
       "      <th>acq_instrument</th>\n",
       "      <th>acq_author</th>\n",
       "      <th>acq_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[t]</td>\n",
       "      <td>[t]</td>\n",
       "      <td>[t]</td>\n",
       "      <td>[t]</td>\n",
       "      <td>[f]</td>\n",
       "      <td>[f]</td>\n",
       "      <td>[f]</td>\n",
       "      <td>[f]</td>\n",
       "      <td>[f]</td>\n",
       "      <td>[f]</td>\n",
       "      <td>...</td>\n",
       "      <td>[f]</td>\n",
       "      <td>[f]</td>\n",
       "      <td>[f]</td>\n",
       "      <td>[f]</td>\n",
       "      <td>[f]</td>\n",
       "      <td>[f]</td>\n",
       "      <td>[f]</td>\n",
       "      <td>[t]</td>\n",
       "      <td>[t]</td>\n",
       "      <td>[t]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20250127_174616.568.0.png</td>\n",
       "      <td>20250127_174616.568.0</td>\n",
       "      <td>20250127</td>\n",
       "      <td>174616</td>\n",
       "      <td>26.8771</td>\n",
       "      <td>-82.8894</td>\n",
       "      <td>51.203804</td>\n",
       "      <td>19.600698</td>\n",
       "      <td>628.0</td>\n",
       "      <td>0.364936</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>142.890039</td>\n",
       "      <td>98.736111</td>\n",
       "      <td>38.108974</td>\n",
       "      <td>45.83547</td>\n",
       "      <td>44.467949</td>\n",
       "      <td>21.687068</td>\n",
       "      <td>CPICS</td>\n",
       "      <td>Enrique Montes (NOAA AOML)</td>\n",
       "      <td>export_4560_20250911_0010_sfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20250127_174617.260.0.png</td>\n",
       "      <td>20250127_174617.260.0</td>\n",
       "      <td>20250127</td>\n",
       "      <td>174617</td>\n",
       "      <td>26.8771</td>\n",
       "      <td>-82.8894</td>\n",
       "      <td>124.038612</td>\n",
       "      <td>19.411459</td>\n",
       "      <td>1507.0</td>\n",
       "      <td>0.21699</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>54.962349</td>\n",
       "      <td>107.958821</td>\n",
       "      <td>24.688127</td>\n",
       "      <td>33.75439</td>\n",
       "      <td>35.553512</td>\n",
       "      <td>14.489614</td>\n",
       "      <td>CPICS</td>\n",
       "      <td>Enrique Montes (NOAA AOML)</td>\n",
       "      <td>export_4560_20250911_0010_sfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20250127_174617.864.0.png</td>\n",
       "      <td>20250127_174617.864.0</td>\n",
       "      <td>20250127</td>\n",
       "      <td>174617</td>\n",
       "      <td>26.8771</td>\n",
       "      <td>-82.8894</td>\n",
       "      <td>30.025755</td>\n",
       "      <td>27.661806</td>\n",
       "      <td>629.0</td>\n",
       "      <td>0.702371</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>204.216392</td>\n",
       "      <td>111.376705</td>\n",
       "      <td>47.460227</td>\n",
       "      <td>52.614773</td>\n",
       "      <td>45.230682</td>\n",
       "      <td>34.7886</td>\n",
       "      <td>CPICS</td>\n",
       "      <td>Enrique Montes (NOAA AOML)</td>\n",
       "      <td>export_4560_20250911_0010_sfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20250127_174645.761.0.png</td>\n",
       "      <td>20250127_174645.761.0</td>\n",
       "      <td>20250127</td>\n",
       "      <td>174645</td>\n",
       "      <td>26.8771</td>\n",
       "      <td>-82.8894</td>\n",
       "      <td>142.024139</td>\n",
       "      <td>18.894503</td>\n",
       "      <td>1992.5</td>\n",
       "      <td>0.236171</td>\n",
       "      <td>...</td>\n",
       "      <td>78</td>\n",
       "      <td>48.962889</td>\n",
       "      <td>107.934524</td>\n",
       "      <td>23.073016</td>\n",
       "      <td>32.398909</td>\n",
       "      <td>34.063889</td>\n",
       "      <td>11.22437</td>\n",
       "      <td>CPICS</td>\n",
       "      <td>Enrique Montes (NOAA AOML)</td>\n",
       "      <td>export_4560_20250911_0010_sfer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               img_file_name              object_id object_date object_time  \\\n",
       "0                        [t]                    [t]         [t]         [t]   \n",
       "1  20250127_174616.568.0.png  20250127_174616.568.0    20250127      174616   \n",
       "2  20250127_174617.260.0.png  20250127_174617.260.0    20250127      174617   \n",
       "3  20250127_174617.864.0.png  20250127_174617.864.0    20250127      174617   \n",
       "4  20250127_174645.761.0.png  20250127_174645.761.0    20250127      174645   \n",
       "\n",
       "  object_lat object_lon object_major object_minor object_area  \\\n",
       "0        [f]        [f]          [f]          [f]         [f]   \n",
       "1    26.8771   -82.8894    51.203804    19.600698       628.0   \n",
       "2    26.8771   -82.8894   124.038612    19.411459      1507.0   \n",
       "3    26.8771   -82.8894    30.025755    27.661806       629.0   \n",
       "4    26.8771   -82.8894   142.024139    18.894503      1992.5   \n",
       "\n",
       "  object_circularity  ... object_height object_sharpness object_saturation  \\\n",
       "0                [f]  ...           [f]              [f]               [f]   \n",
       "1           0.364936  ...            46       142.890039         98.736111   \n",
       "2            0.21699  ...            86        54.962349        107.958821   \n",
       "3           0.702371  ...            30       204.216392        111.376705   \n",
       "4           0.236171  ...            78        48.962889        107.934524   \n",
       "\n",
       "  object_redness object_greeness object_blueness object_colorfulness  \\\n",
       "0            [f]             [f]             [f]                 [f]   \n",
       "1      38.108974        45.83547       44.467949           21.687068   \n",
       "2      24.688127        33.75439       35.553512           14.489614   \n",
       "3      47.460227       52.614773       45.230682             34.7886   \n",
       "4      23.073016       32.398909       34.063889            11.22437   \n",
       "\n",
       "  acq_instrument                  acq_author                          acq_id  \n",
       "0            [t]                         [t]                             [t]  \n",
       "1          CPICS  Enrique Montes (NOAA AOML)  export_4560_20250911_0010_sfer  \n",
       "2          CPICS  Enrique Montes (NOAA AOML)  export_4560_20250911_0010_sfer  \n",
       "3          CPICS  Enrique Montes (NOAA AOML)  export_4560_20250911_0010_sfer  \n",
       "4          CPICS  Enrique Montes (NOAA AOML)  export_4560_20250911_0010_sfer  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 5. Create Final Metadata and Format for Export\n",
    "\n",
    "# --- Create the dynamic acquisition ID ---\n",
    "# Count the total number of .png files in the directory\n",
    "total_png_files = len(glob.glob(os.path.join(dir_path, \"**\", \"*.png\"), recursive=True))\n",
    "\n",
    "# Get the current GMT/UTC time and format it\n",
    "utc_now = datetime.now(timezone.utc)\n",
    "timestamp_str = utc_now.strftime('%Y%m%d_%H%M')\n",
    "\n",
    "# Construct the final acq_id string\n",
    "acq_id_str = f\"export_{total_png_files}_{timestamp_str}_sfer\"\n",
    "print(f\"Generated Acquisition ID: {acq_id_str}\")\n",
    "\n",
    "\n",
    "# --- Add and format final metadata columns ---\n",
    "final_table['acq_instrument'] = \"CPICS\"\n",
    "final_table['acq_author'] = \"Enrique Montes (NOAA AOML)\"\n",
    "final_table['acq_id'] = acq_id_str\n",
    "\n",
    "# Create other required columns from existing data\n",
    "final_table['object_id'] = final_table['img_file_name'].str.slice(0, 21)\n",
    "final_table['object_date'] = final_table['datetime'].dt.strftime('%Y%m%d')\n",
    "final_table['object_time'] = final_table['datetime'].dt.strftime('%H%M%S')\n",
    "\n",
    "# Rename SFER columns to match the final EcoTaxa format (depth columns removed)\n",
    "final_table = final_table.rename(columns={\n",
    "    'lat_dec': 'object_lat',\n",
    "    'lon_dec': 'object_lon'\n",
    "})\n",
    "\n",
    "# --- Define the exact columns and order for the EcoTaxa table (depth columns removed) ---\n",
    "ecotaxa_cols = {\n",
    "    'img_file_name': '[t]', 'object_id': '[t]', 'object_date': '[t]', 'object_time': '[t]',\n",
    "    'object_lat': '[f]', 'object_lon': '[f]',\n",
    "    'object_major': '[f]', 'object_minor': '[f]', 'object_area': '[f]', 'object_circularity': '[f]',\n",
    "    'object_perimeter': '[f]', 'object_width': '[f]', 'object_height': '[f]', 'object_sharpness': '[f]',\n",
    "    'object_saturation': '[f]', 'object_redness': '[f]', 'object_greeness': '[f]', 'object_blueness': '[f]',\n",
    "    'object_colorfulness': '[f]', 'acq_instrument': '[t]', 'acq_author': '[t]', 'acq_id': '[t]'\n",
    "}\n",
    "\n",
    "# Create the format codes header row as a DataFrame\n",
    "format_codes_df = pd.DataFrame([ecotaxa_cols])\n",
    "\n",
    "# Select and order the data columns from the master DataFrame\n",
    "ecotaxa_data = final_table[ecotaxa_cols.keys()]\n",
    "\n",
    "# Combine the header and data\n",
    "ecotaxa_table = pd.concat([format_codes_df, ecotaxa_data], ignore_index=True)\n",
    "\n",
    "print(\"\\nFinal EcoTaxa table created. Sample:\")\n",
    "ecotaxa_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e01360d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4560 unique filenames listed in the final table.\n",
      "Found 4560 actual .png files on disk.\n",
      "\n",
      "✅ Success: All files listed in the 'ecotaxa_table' are present in the 'classified_output' directory.\n"
     ]
    }
   ],
   "source": [
    "## 6. Validation Check: Verify All Files Exist\n",
    "\n",
    "# --- Step 1: Get the list of filenames from the EcoTaxa table ---\n",
    "# Skip the first row (which contains format codes) and get the 'img_file_name' column\n",
    "try:\n",
    "    filenames_in_table = set(ecotaxa_table['img_file_name'].iloc[1:])\n",
    "    print(f\"Found {len(filenames_in_table)} unique filenames listed in the final table.\")\n",
    "except NameError:\n",
    "    print(\"Error: The 'ecotaxa_table' DataFrame does not exist. Please run the previous cells first.\")\n",
    "    # Stop execution if the table isn't created\n",
    "    filenames_in_table = set()\n",
    "\n",
    "\n",
    "if filenames_in_table:\n",
    "    # --- Step 2: Get the list of all .png files physically present in the directory ---\n",
    "    dir_path = \"classified_output\"\n",
    "    \n",
    "    # Use glob to recursively find all .png files and get just their names\n",
    "    actual_files_on_disk = set(\n",
    "        os.path.basename(p) for p in glob.glob(os.path.join(dir_path, \"**\", \"*.png\"), recursive=True)\n",
    "    )\n",
    "    print(f\"Found {len(actual_files_on_disk)} actual .png files on disk.\")\n",
    "\n",
    "    # --- Step 3: Compare the lists to find missing files ---\n",
    "    missing_files = filenames_in_table.difference(actual_files_on_disk)\n",
    "\n",
    "    # --- Step 4: Report the results ---\n",
    "    if not missing_files:\n",
    "        print(\"\\n✅ Success: All files listed in the 'ecotaxa_table' are present in the 'classified_output' directory.\")\n",
    "    else:\n",
    "        print(f\"\\n⚠️ Warning: Found {len(missing_files)} missing files.\")\n",
    "        print(\"The following files are listed in the table but were not found on disk:\")\n",
    "        # Print the first 10 missing files for brevity\n",
    "        for i, filename in enumerate(missing_files):\n",
    "            if i < 10:\n",
    "                print(f\" - {filename}\")\n",
    "        if len(missing_files) > 10:\n",
    "            print(f\"   ...and {len(missing_files) - 10} more.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9ca4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Save the Final EcoTaxa Table and the merged DataFrame with SFER Data\n",
    "\n",
    "# Define the output path for the final TSV file\n",
    "destination_path = os.path.join(os.path.expanduser(\"~\"), \"plankton_imaging\")\n",
    "output_path_ecotaxa = os.path.join(destination_path, \"ecotaxa_sfer-mbon.tsv\")\n",
    "output_path_merged = os.path.join(destination_path, \"merged_sfer-mbon.tsv\")\n",
    "\n",
    "# Save the final table\n",
    "ecotaxa_table.to_csv(output_path_ecotaxa, sep='\\t', index=False, quoting=csv.QUOTE_NONE)\n",
    "final_table.to_csv(output_path_merged, sep='\\t', index=False, quoting=csv.QUOTE_NONE)\n",
    "\n",
    "print(f\"\\nSuccessfully created the final merged table at: {output_path_ecotaxa}\")\n",
    "print(f\"\\nSuccessfully created the final merged table at: {output_path_merged}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f598567f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting EcoTaxa Packaging Routine ---\n",
      "Creating temporary packaging folder: /space/home/enrique.montes@CNS.local/plankton_imaging/ecotaxa_package\n",
      "Copying TSV table: ecotaxa_sfer-mbon.tsv\n",
      "Finding all .png files in '/space/home/enrique.montes@CNS.local/plankton_imaging/classified_output'...\n",
      "Found 4560 images. Copying to package folder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████| 4560/4560 [00:03<00:00, 1256.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image copying complete.\n",
      "\n",
      "Compressing 'ecotaxa_package' into a zip archive...\n",
      "✅ Success! Archive created at: /space/home/enrique.montes@CNS.local/plankton_imaging/ecotaxa_package.zip\n",
      "Cleaning up temporary directory...\n",
      "\n",
      "--- Packaging Complete! ---\n"
     ]
    }
   ],
   "source": [
    "# Create a zip archive containing all classified PNG files and the final TSV table\n",
    "def package_ecotaxa_results():\n",
    "    \"\"\"\n",
    "    Aggregates all classified PNG files and the final TSV table into a\n",
    "    single folder, then compresses that folder into a zip archive.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting EcoTaxa Packaging Routine ---\")\n",
    "\n",
    "    # --- 1. Define Paths ---\n",
    "    # Assumes the script is run from the directory containing 'classified_output'\n",
    "    base_dir = Path.cwd() \n",
    "    source_images_dir = base_dir / \"classified_output\"\n",
    "    landing_path = Path(os.path.expanduser(\"~\")) / \"plankton_imaging\"\n",
    "    source_tsv_file = landing_path / \"ecotaxa_sfer-mbon.tsv\"\n",
    "\n",
    "    # Define the temporary packaging folder and final zip file name\n",
    "    package_dir = base_dir / \"ecotaxa_package\"\n",
    "    zip_output_name = \"ecotaxa_package\"\n",
    "\n",
    "    # --- 2. Setup Packaging Directory ---\n",
    "    print(f\"Creating temporary packaging folder: {package_dir}\")\n",
    "    # Remove the directory if it exists to ensure a clean start\n",
    "    if package_dir.exists():\n",
    "        shutil.rmtree(package_dir)\n",
    "    package_dir.mkdir()\n",
    "\n",
    "    # --- 3. Copy the TSV Table ---\n",
    "    if source_tsv_file.exists():\n",
    "        print(f\"Copying TSV table: {source_tsv_file.name}\")\n",
    "        shutil.copy(source_tsv_file, package_dir)\n",
    "    else:\n",
    "        print(f\"⚠️ Warning: TSV file not found at {source_tsv_file}. It will be missing from the package.\")\n",
    "\n",
    "    # --- 4. Find and Copy all PNG Files ---\n",
    "    print(f\"Finding all .png files in '{source_images_dir}'...\")\n",
    "    png_files_to_copy = list(source_images_dir.rglob(\"*.png\"))\n",
    "\n",
    "    if not png_files_to_copy:\n",
    "        print(\"⚠️ Warning: No .png files were found in the 'classified_output' directory.\")\n",
    "    else:\n",
    "        print(f\"Found {len(png_files_to_copy)} images. Copying to package folder...\")\n",
    "        # Use tqdm for a progress bar during the copy operation\n",
    "        for file_path in tqdm(png_files_to_copy, desc=\"Copying images\"):\n",
    "            shutil.copy(file_path, package_dir)\n",
    "        print(\"Image copying complete.\")\n",
    "\n",
    "    # --- 5. Compress the Packaging Folder ---\n",
    "    print(f\"\\nCompressing '{package_dir.name}' into a zip archive...\")\n",
    "    try:\n",
    "        shutil.make_archive(zip_output_name, 'zip', package_dir)\n",
    "        final_zip_path = base_dir / f\"{zip_output_name}.zip\"\n",
    "        print(f\"✅ Success! Archive created at: {final_zip_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: Failed to create zip archive. Reason: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 6. Clean Up Temporary Folder ---\n",
    "    print(f\"Cleaning up temporary directory...\")\n",
    "    shutil.rmtree(package_dir)\n",
    "    \n",
    "    print(\"\\n--- Packaging Complete! ---\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # To run this script, first install the 'tqdm' library if you haven't already:\n",
    "    # pip install tqdm\n",
    "    package_ecotaxa_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feat_ext",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
