{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "648ae2f3",
   "metadata": {},
   "source": [
    "## This notebook creates a table with monthly seascape class and cruise metadata, and renders data visualizations and seascape maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ce3cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.stats import mode as sp_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd9dd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SFER data\n",
    "# Define the path to the data file\n",
    "ctd_file = Path('~/plankton_imaging/ctd_meta_v4.csv').expanduser()\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "ctd_df = pd.read_csv(ctd_file)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify it loaded correctly\n",
    "ctd_df.head()\n",
    "\n",
    "# Print few rows of the DataFrame to verify it loaded correctly\n",
    "print(ctd_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fee514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this variable to 'SEASCAPE_MONTH' or 'SEASCAPE_8DAY' as needed\n",
    "dataset_type = 'SEASCAPE_8DAY' \n",
    "\n",
    "# Define Domain Limits and Dates \n",
    "n_lat = 29\n",
    "s_lat = 23\n",
    "e_lon = -79.5\n",
    "w_lon = -86\n",
    "start_date = '2022-11-15T12:00:00Z'\n",
    "end_date = '2025-10-15T12:00:00Z'\n",
    "\n",
    "# Build the Request for the MONTHLY Product \n",
    "print(f\"Configuring request for: {dataset_type}\")\n",
    "\n",
    "base_url = f\"https://cwcgom.aoml.noaa.gov/thredds/ncss/{dataset_type}/SEASCAPES.nc\"\n",
    "\n",
    "params = {\n",
    "    'var': ['CLASS', 'P'],\n",
    "    'north': n_lat,\n",
    "    'west': w_lon,\n",
    "    'east': e_lon,\n",
    "    'south': s_lat,\n",
    "    'disableProjSubset': 'on',\n",
    "    'horizStride': 1,\n",
    "    'time_start': start_date,\n",
    "    'time_end': end_date,\n",
    "    'timeStride': 1,\n",
    "    'addLatLon': 'true',\n",
    "    'accept': 'netcdf',\n",
    "}\n",
    "\n",
    "req = requests.Request('GET', base_url, params=params).prepare()\n",
    "url = req.url\n",
    "\n",
    "print(\"Requesting data from URL:\")\n",
    "print(url)\n",
    "\n",
    "# Download the Data Manually and Then Open ---\n",
    "output_filename = 'seascape_data.nc'\n",
    "\n",
    "try:\n",
    "    # Download the file using requests\n",
    "    print(f\"\\nDownloading data to '{output_filename}'...\")\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()  # This will raise an error for bad status codes\n",
    "        with open(output_filename, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "    print(\"Download complete.\")\n",
    "\n",
    "    # Open the local file with xarray\n",
    "    ds = xr.open_dataset(output_filename)\n",
    "    print(\"\\nSuccessfully loaded dataset from local file:\")\n",
    "    print(ds)\n",
    "\n",
    "    # Analyze Unique Classes ---\n",
    "    class_data = ds['CLASS'].values\n",
    "    unique_classes_with_nan = np.unique(class_data)\n",
    "    unique_classes = unique_classes_with_nan[~np.isnan(unique_classes_with_nan)]\n",
    "\n",
    "    print(\"\\nUnique classes present in CLASS:\")\n",
    "    print(unique_classes.astype(int))\n",
    "\n",
    "except Exception as err:\n",
    "    print(f\"\\nAn error occurred: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e2303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TIMEVEC DataFrame.\n",
    "# Access the time coordinate from the xarray dataset\n",
    "time_coordinate = ds['time']\n",
    "\n",
    "# Create a dictionary with the year, month, day, and full datetime\n",
    "time_data = {\n",
    "    'year': time_coordinate.dt.year.values,\n",
    "    'month': time_coordinate.dt.month.values,\n",
    "    'day': time_coordinate.dt.day.values,\n",
    "    'datetime': time_coordinate.values\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a pandas DataFrame\n",
    "TIMEVEC = pd.DataFrame(time_data)\n",
    "\n",
    "print(\"Created TIMEVEC DataFrame:\")\n",
    "print(TIMEVEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ad620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Map Seascape Data for a Single Time Step as a test\n",
    "\n",
    "# Select the Data for a Single Time Step \n",
    "seascape_selected = ds.isel(time=0)\n",
    "\n",
    "# --- Prepare Colormap and Normalization ---\n",
    "# Get the unique, non-NaN classes from the selected data\n",
    "class_values = seascape_selected['CLASS'].values\n",
    "unique_with_nan = np.unique(class_values)\n",
    "unique_classes = unique_with_nan[~np.isnan(unique_with_nan)]\n",
    "\n",
    "# Define the colormap and create a BoundaryNorm object\n",
    "# This ensures each class number maps to a specific, consistent color\n",
    "cmap = plt.get_cmap('tab20')\n",
    "# CORRECTED: Added the '- 0.5' to center the ticks\n",
    "bounds = np.append(unique_classes, unique_classes[-1] + 1)\n",
    "norm = BoundaryNorm(bounds, ncolors=cmap.N)\n",
    "\n",
    "# --- Set Up the Map ---\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "ax.set_extent([w_lon, e_lon, s_lat, n_lat], crs=ccrs.PlateCarree())\n",
    "\n",
    "# --- Plot the Seascape Data ---\n",
    "# Pass the normalization object ('norm') to ensure correct color mapping\n",
    "mesh = ax.pcolormesh(\n",
    "    seascape_selected['lon'], \n",
    "    seascape_selected['lat'], \n",
    "    seascape_selected['CLASS'],\n",
    "    cmap=cmap,\n",
    "    norm=norm, # Apply the normalization rule\n",
    "    transform=ccrs.PlateCarree()\n",
    ")\n",
    "\n",
    "# --- Add Map Features ---\n",
    "ax.add_feature(cfeature.LAND, zorder=1, edgecolor='black', facecolor='tan')\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                  linewidth=1, color='gray', alpha=0.5, linestyle='--')\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "gl.xlabel_style = {'size': 12}\n",
    "gl.ylabel_style = {'size': 12}\n",
    "\n",
    "# --- Add Colorbar and Title ---\n",
    "# The colorbar will automatically use the correct normalization from 'mesh'\n",
    "cbar = plt.colorbar(mesh, ax=ax, ticks=unique_classes)\n",
    "cbar.set_label('Seascape Class ID', fontsize=12, weight='bold')\n",
    "\n",
    "# Get the date from the selected data\n",
    "seascape_date = pd.to_datetime(seascape_selected.time.values).strftime('%Y-%m-%d')\n",
    "\n",
    "# Set the title using the extracted date\n",
    "ax.set_title(f'Seascapes for {seascape_date}', fontsize=16, weight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1893cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's define the parameters and prepare the data structures needed for the analysis.\n",
    "\n",
    "# --- Parameters ---\n",
    "N_PIXELS = 3  # Radius in pixels to search around each station\n",
    "PIX_RESOLUTION_DEG = 0.0416 # Approximate resolution of 4-km seascapes in degrees\n",
    "SEARCH_RADIUS_DEG = N_PIXELS * PIX_RESOLUTION_DEG\n",
    "\n",
    "# Prepare the seascape grid coordinates for efficient searching\n",
    "# Flatten the lat/lon grid into a list of (lat, lon) points\n",
    "lon_grid, lat_grid = np.meshgrid(ds['lon'].values, ds['lat'].values)\n",
    "grid_points = np.vstack([lat_grid.ravel(), lon_grid.ravel()]).T\n",
    "\n",
    "# Create a KD-Tree for fast nearest-neighbor searches. This is much faster\n",
    "# than calculating the distance to every single grid point.\n",
    "kdtree = KDTree(grid_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9f9dd2",
   "metadata": {},
   "source": [
    "### USE THE NEXT CELL FOR MONTHLY SEASCAPE EXTRACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740fcc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR MONTHLY EXTRACTIONS: This loop iterates through each month, creates the map,\n",
    "#  and performs the extraction and analysis.\n",
    "\n",
    "# List to store the final results\n",
    "all_sites_summary_monthly = []\n",
    "\n",
    "# Loop through each time step (month) in the seascape data\n",
    "for i, t_row in TIMEVEC.iterrows():\n",
    "    current_year = t_row['year']\n",
    "    current_month = t_row['month']\n",
    "\n",
    "    # --- Find corresponding cruise data for this month ---\n",
    "    # Filter using the existing 'year' and 'month' columns, and exclude 'F' type stations\n",
    "    monthly_cruise_df = ctd_df[\n",
    "        (ctd_df['year'] == current_year) &\n",
    "        (ctd_df['month'] == current_month) \n",
    "    ].copy()\n",
    "\n",
    "    if monthly_cruise_df.empty:\n",
    "        print(f\"No cruise data for {current_year}-{current_month:02d}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing {len(monthly_cruise_df)} stations for {current_year}-{current_month:02d}...\")\n",
    "\n",
    "    seascape_monthly = ds.isel(time=i)\n",
    "    \n",
    "    # # --- A. Create the Map ---\n",
    "    # fig = plt.figure(figsize=(10, 8))\n",
    "    # ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "    # ax.set_extent([w_lon, e_lon, s_lat, n_lat], crs=ccrs.PlateCarree())\n",
    "    \n",
    "    # # Prepare BoundaryNorm for correct categorical coloring\n",
    "    # class_values = seascape_monthly['CLASS'].values\n",
    "    # unique_with_nan = np.unique(class_values)\n",
    "    # unique_classes = unique_with_nan[~np.isnan(unique_with_nan)]\n",
    "    # cmap = plt.get_cmap('tab20')\n",
    "    # bounds = np.append(unique_classes, unique_classes[-1] + 1)\n",
    "    # norm = BoundaryNorm(bounds, ncolors=cmap.N)\n",
    "\n",
    "    # mesh = ax.pcolormesh(\n",
    "    #     seascape_monthly['lon'], seascape_monthly['lat'], seascape_monthly['CLASS'],\n",
    "    #     cmap=cmap, norm=norm, transform=ccrs.PlateCarree()\n",
    "    # )\n",
    "    \n",
    "    # cbar = plt.colorbar(mesh, ax=ax, ticks=unique_classes, pad=0.05, aspect=25)\n",
    "    # cbar.set_label('Seascape Class ID', fontsize=12)\n",
    "    # ax.add_feature(cfeature.LAND, zorder=1, edgecolor='black', facecolor='tan')\n",
    "    # ax.add_feature(cfeature.COASTLINE)\n",
    "    # ax.gridlines(draw_labels=True, linestyle='--')\n",
    "    # ax.scatter(\n",
    "    #     monthly_cruise_df['lon_dec'], monthly_cruise_df['lat_dec'],\n",
    "    #     s=50, c='black', marker='*', transform=ccrs.PlateCarree(),\n",
    "    #     label='Cruise Stations'\n",
    "    # )\n",
    "    # ax.set_title(f\"Seascapes and Stations: {current_year}-{current_month:02d}\", fontsize=16)\n",
    "    # plt.savefig(f\"{current_year}-{current_month:02d}_map.png\", dpi=150, bbox_inches='tight')\n",
    "    # plt.close(fig)\n",
    "\n",
    "    # --- B. Extract Surrounding Seascape Pixels ---\n",
    "    station_points = monthly_cruise_df[['dec_lat', 'dec_lon']].values\n",
    "    nearby_indices_list = kdtree.query_ball_point(station_points, r=SEARCH_RADIUS_DEG)\n",
    "    monthly_cruise_df['nearby_grid_indices'] = nearby_indices_list\n",
    "    \n",
    "    # --- C. Calculate Modal Seascape Class ---\n",
    "    site_summaries = []\n",
    "    for idx, station in monthly_cruise_df.iterrows():\n",
    "        flat_indices = station['nearby_grid_indices']\n",
    "        \n",
    "        # Check if any grid cells were found nearby\n",
    "        if not flat_indices:\n",
    "            # Case 1: No grid cells within search radius. Assign NaN and record.\n",
    "            modal_class = np.nan\n",
    "            mean_prob_of_modal = np.nan\n",
    "        else:\n",
    "            # Grid cells were found, now check if they are valid (not NaN)\n",
    "            rows, cols = np.unravel_index(flat_indices, seascape_monthly['CLASS'].shape)\n",
    "            nearby_classes = seascape_monthly['CLASS'].values[rows, cols]\n",
    "            nearby_probs = seascape_monthly['P'].values[rows, cols]\n",
    "            \n",
    "            valid_mask = ~np.isnan(nearby_classes)\n",
    "            valid_classes = nearby_classes[valid_mask]\n",
    "            \n",
    "            if valid_classes.size > 0:\n",
    "                # Case 2: Valid (non-NaN) grid cells exist. Compute mode.\n",
    "                modal_class = sp_mode(valid_classes, keepdims=False).mode\n",
    "                valid_probs = nearby_probs[valid_mask]\n",
    "                probs_of_modal_class = valid_probs[valid_classes == modal_class]\n",
    "                mean_prob_of_modal = np.mean(probs_of_modal_class)\n",
    "            else:\n",
    "                # Case 3: All nearby grid cells were NaN. Assign NaN and record.\n",
    "                modal_class = np.nan\n",
    "                mean_prob_of_modal = np.nan\n",
    "\n",
    "        # Append the result for the station, covering all cases to ensure no station is skipped\n",
    "        site_summaries.append({\n",
    "            'cruise_id': station['cruiseID'],\n",
    "            'station': station['Station'],\n",
    "            'year': station['year'],\n",
    "            'month': station['month'],\n",
    "            'day': station['day'],\n",
    "            'time': station['time_gmt'],\n",
    "            'lat_dec': station['dec_lat'],\n",
    "            'lon_dec': station['dec_lon'],\n",
    "            'modal_seascape_class': modal_class,\n",
    "            'mean_seascape_prob': mean_prob_of_modal\n",
    "        })\n",
    "\n",
    "    all_sites_summary_monthly.extend(site_summaries)\n",
    "\n",
    "# Convert the final list of results into a pandas DataFrame\n",
    "conc_class_per_site_monthly = pd.DataFrame(all_sites_summary_monthly)\n",
    "\n",
    "# Define the output filename\n",
    "output_filename = \"seascape_station_summary_monthly.tsv\"\n",
    "\n",
    "# Save the DataFrame to a .tsv file\n",
    "# sep='\\t' specifies a tab separator, and index=False prevents writing the row numbers\n",
    "# conc_class_per_site_monthly.to_csv(output_filename, sep='\\t', index=False)\n",
    "\n",
    "print(\"\\n--- Analysis Complete ---\")\n",
    "print(\"Final summary of modal seascape classes for 'C' type stations:\")\n",
    "print(conc_class_per_site_monthly.head())\n",
    "print(f\"\\nResults saved to '{output_filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3315da0c",
   "metadata": {},
   "source": [
    "### USE THE NEXT CELL FOR 8-DAY SEASCAPE EXTRACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9566449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR 8-DAY EXTRACTIONS: Loop through each 8-day time window\n",
    "# Convert cruise data dates to datetime objects ---\n",
    "# This step is essential for comparing cruise dates to the 8-day seascape windows.\n",
    "ctd_df['datetime'] = pd.to_datetime(ctd_df[['year', 'month', 'day']])\n",
    "\n",
    "# Prepare for Storing Results ---\n",
    "all_sites_summary_8day = []\n",
    "\n",
    "# We stop at -1 because each window is defined by a start (i) and end (i+1) time\n",
    "for i in range(len(ds.time) - 1):\n",
    "    start_date = ds.time.values[i]\n",
    "    end_date = ds.time.values[i+1]\n",
    "\n",
    "    # --- Find corresponding cruise data within the 8-day window ---\n",
    "    cruise_in_window_df = ctd_df[\n",
    "        (ctd_df['datetime'] >= start_date) & \n",
    "        (ctd_df['datetime'] < end_date)\n",
    "    ].copy()\n",
    "\n",
    "    if cruise_in_window_df.empty:\n",
    "        print(f\"No cruise data for window starting {pd.to_datetime(start_date).strftime('%Y-%m-%d')}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing {len(cruise_in_window_df)} stations for window starting {pd.to_datetime(start_date).strftime('%Y-%m-%d')}...\")\n",
    "\n",
    "    # Select the seascape data for the current time step\n",
    "    seascape_8day = ds.isel(time=i)\n",
    "    \n",
    "    # --- A. Create the Map ---\n",
    "    # fig = plt.figure(figsize=(10, 8))\n",
    "    # ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "    # ax.set_extent([w_lon, e_lon, s_lat, n_lat], crs=ccrs.PlateCarree())\n",
    "    \n",
    "    # # Use BoundaryNorm for correct categorical coloring\n",
    "    # class_values = seascape_8day['CLASS'].values\n",
    "    # unique_with_nan = np.unique(class_values)\n",
    "    # unique_classes = unique_with_nan[~np.isnan(unique_with_nan)]\n",
    "    # cmap = plt.get_cmap('tab20')\n",
    "    # if unique_classes.size > 0:\n",
    "    #     bounds = np.append(unique_classes, unique_classes[-1] + 1) - 0.5\n",
    "    #     norm = BoundaryNorm(bounds, ncolors=cmap.N)\n",
    "    #     mesh = ax.pcolormesh(seascape_8day['lon'], seascape_8day['lat'], seascape_8day['CLASS'], cmap=cmap, norm=norm, transform=ccrs.PlateCarree())\n",
    "    #     cbar = plt.colorbar(mesh, ax=ax, ticks=unique_classes, pad=0.05, aspect=25)\n",
    "    #     cbar.set_label('Seascape Class ID', fontsize=12)\n",
    "\n",
    "    # ax.add_feature(cfeature.LAND, zorder=1, edgecolor='black', facecolor='tan')\n",
    "    # ax.add_feature(cfeature.COASTLINE)\n",
    "    # ax.gridlines(draw_labels=True, linestyle='--')\n",
    "    # ax.scatter(cruise_in_window_df['lon_dec'], cruise_in_window_df['lat_dec'], s=50, c='black', marker='*', transform=ccrs.PlateCarree(), label='Cruise Stations')\n",
    "    # ax.set_title(f\"Seascapes and 'C' Stations: {pd.to_datetime(start_date).strftime('%Y-%m-%d')}\", fontsize=16)\n",
    "    # plt.savefig(f\"{pd.to_datetime(start_date).strftime('%Y-%m-%d')}_C_stations_map.png\", dpi=150, bbox_inches='tight')\n",
    "    # plt.close(fig)\n",
    "\n",
    "    # --- B. Extract Surrounding Seascape Pixels ---\n",
    "    station_points = cruise_in_window_df[['dec_lat', 'dec_lon']].values\n",
    "    nearby_indices_list = kdtree.query_ball_point(station_points, r=SEARCH_RADIUS_DEG)\n",
    "    cruise_in_window_df['nearby_grid_indices'] = nearby_indices_list\n",
    "    \n",
    "    # --- C. Calculate Modal Seascape Class ---\n",
    "    site_summaries = []\n",
    "    for idx, station in cruise_in_window_df.iterrows():\n",
    "        flat_indices = station['nearby_grid_indices']\n",
    "        \n",
    "        # Check if any grid cells were found nearby\n",
    "        if not flat_indices:\n",
    "            # Case 1: No grid cells within search radius. Assign NaN.\n",
    "            modal_class = np.nan\n",
    "            mean_prob_of_modal = np.nan\n",
    "        else:\n",
    "            # Grid cells were found, now check if they are valid (not NaN)\n",
    "            rows, cols = np.unravel_index(flat_indices, seascape_8day['CLASS'].shape)\n",
    "            nearby_classes = seascape_8day['CLASS'].values[rows, cols]\n",
    "            nearby_probs = seascape_8day['P'].values[rows, cols]\n",
    "            \n",
    "            valid_mask = ~np.isnan(nearby_classes)\n",
    "            valid_classes = nearby_classes[valid_mask]\n",
    "            \n",
    "            if valid_classes.size > 0:\n",
    "                # Case 2: Valid (non-NaN) grid cells exist. Compute mode.\n",
    "                modal_class = sp_mode(valid_classes, keepdims=False).mode\n",
    "                valid_probs = nearby_probs[valid_mask]\n",
    "                probs_of_modal_class = valid_probs[valid_classes == modal_class]\n",
    "                mean_prob_of_modal = np.mean(probs_of_modal_class)\n",
    "            else:\n",
    "                # Case 3: All nearby grid cells were NaN. Assign NaN.\n",
    "                modal_class = np.nan\n",
    "                mean_prob_of_modal = np.nan\n",
    "\n",
    "        # Append the result for the station, covering all cases to ensure no station is skipped\n",
    "        site_summaries.append({\n",
    "            'cruise_id': station['cruiseID'],\n",
    "            'station': station['Station'],\n",
    "            'year': station['year'], \n",
    "            'month': station['month'], \n",
    "            'day': station['day'],\n",
    "            'time': station['time_gmt'],\n",
    "            'lat_dec': station['dec_lat'], \n",
    "            'lon_dec': station['dec_lon'],\n",
    "            'modal_seascape_class': modal_class, \n",
    "            'mean_seascape_prob': mean_prob_of_modal\n",
    "        })\n",
    "    all_sites_summary_8day.extend(site_summaries)\n",
    "\n",
    "# Convert the final list of results into a pandas DataFrame\n",
    "conc_class_per_site_8day = pd.DataFrame(all_sites_summary_8day)\n",
    "\n",
    "# Define the output filename\n",
    "output_filename = \"seascape_station_summary_8day.tsv\"\n",
    "\n",
    "# Save the DataFrame to a .tsv file\n",
    "# sep='\\t' specifies a tab separator, and index=False prevents writing the row numbers\n",
    "# conc_class_per_site_8day.to_csv(output_filename, sep='\\t', index=False)\n",
    "\n",
    "print(\"\\n--- 8-Day Analysis Complete ---\")\n",
    "print(\"Final summary of modal seascape classes for 'C' type stations:\")\n",
    "print(conc_class_per_site_8day.head())\n",
    "print(f\"\\nResults saved to '{output_filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba161f8",
   "metadata": {},
   "source": [
    "## Merge monthly and 8-day seascape tables into a single file. Monthly and 8-day cells must be run prior to this merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7031c68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with the 8-day data as the base\n",
    "merged_df = conc_class_per_site_8day.copy()\n",
    "\n",
    "# Directly append the two columns from the monthly data\n",
    "# This assumes both tables have the exact same row order\n",
    "merged_df['modal_class_monthly'] = conc_class_per_site_monthly['modal_seascape_class']\n",
    "merged_df['mean_prob_monthly'] = conc_class_per_site_monthly['mean_seascape_prob']\n",
    "\n",
    "# remane the columns for 8-day seascapes\n",
    "merged_df.rename(columns={'modal_seascape_class': 'modal_class_8day'}, inplace=True)  \n",
    "merged_df.rename(columns={'mean_seascape_prob': 'mean_prob_8day'}, inplace=True)\n",
    "\n",
    "# --- Save the Final Merged File ---\n",
    "output_filename = \"seascape_station_summary_appended.tsv\"\n",
    "merged_df.to_csv(output_filename, sep='\\t', index=False)\n",
    "\n",
    "print(\"\\n--- Appending Complete ---\")\n",
    "print(\"Final appended summary:\")\n",
    "print(merged_df.head())\n",
    "print(f\"\\nResults saved to '{output_filename}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seas_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
